import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


df = pd.read_csv("smartcart_customers.csv")


df.head()


df.shape


df.isnull().sum()








df["Income"] = df["Income"].fillna(df["Income"].median())


df.isnull().sum()


df.head()





# Customer age

df["Age"] = 2026 - df["Year_Birth"]


df.head()


# Customer Joining date

df["Dt_Customer"] = pd.to_datetime(df["Dt_Customer"], dayfirst=True)

df["Customer_Tenure_Days"] = (pd.Timestamp.now() - df["Dt_Customer"]).dt.days


df.head()


df.columns


# Calc total spending

df["Total_Spending"] = df["MntWines"] + df["MntFruits"] + df["MntMeatProducts"] + df["MntFishProducts"] + df["MntSweetProducts"] + df["MntGoldProds"]


df.head()


# Calc Childern 
df["Total_Children"] = df["Kidhome"] + df["Teenhome"]


df.head()


# Education

df["Education"].value_counts()


df["Education"] = df["Education"].replace({
    "Basic": "Undergraduate", "2n Cycle": "Undergraduate",
    "Graduation": "Graduate",
    "Master": "Postgraduate", "PhD": "Postgraduate"
})   


df["Education"].value_counts()


# Marital status

df["Marital_Status"].value_counts()


df["Living_With"] = df["Marital_Status"].replace({
    "Married": "Partner", "Together": "Partner",
    "Single": "Alone", "Divorced": "Alone",
    "Widow": "Alone", "Absurd": "Alone", "YOLO": "Alone" 
})


df["Living_With"].value_counts()





df_cleaned = df.drop(columns = ["ID", "Year_Birth", "Marital_Status", "Kidhome", "Teenhome", "Dt_Customer","MntWines", "MntFruits", "MntMeatProducts", "MntFishProducts", "MntSweetProducts", "MntGoldProds"])

df_cleaned.shape


df_cleaned.head()





sns.pairplot(df_cleaned[["Income", "Recency", "Response", "Age", "Total_Spending", "Total_Children"]])


# Removing outliers

print("Data size before removing outliers:", len(df_cleaned))

df_cleaned = df_cleaned[(df_cleaned["Age"] < 90)]
df_cleaned = df_cleaned[(df_cleaned["Income"] < 600_000)]

print("Data size after removing outliers:", len(df_cleaned))


# Correlation Heatmap

corr = df_cleaned.corr(numeric_only = True)


plt.figure(figsize=(8,6))

sns.heatmap(
    corr,
    annot=True,
    annot_kws={"size": 6},
    cmap="coolwarm"
)





from sklearn.preprocessing import OneHotEncoder


ohe = OneHotEncoder()

cat_cols = ["Education", "Living_With"]

enc_cols = ohe.fit_transform(df_cleaned[cat_cols])


# converting the encoded value into df

enc_df = pd.DataFrame(enc_cols.toarray(), columns=ohe.get_feature_names_out(cat_cols), index=df_cleaned.index)


enc_df.head()


df_cleaned = df_cleaned.drop(columns=cat_cols)


df_encoded = pd.concat([df_cleaned, enc_df], axis=1)


df_encoded.head()





from sklearn.preprocessing import StandardScaler


X = df_encoded


scaler = StandardScaler()

X_scaled = scaler.fit_transform(X)





X_scaled.shape


# 2D

from sklearn.decomposition import PCA


pca = PCA(n_components=3) #Just change the n_components value to change the dimensions from 1d or 2d or 3d and so on

X_pca = pca.fit_transform(X_scaled)


# plot 

plt.scatter(X_pca[:,0], X_pca[:,1])


pca.explained_variance_ratio_


# 3D

fig = plt.figure(figsize=(8,6))

ax = fig.add_subplot(111, projection="3d")

ax.scatter(X_pca[:,0], X_pca[:,1], X_pca[:,2])
ax.set_xlabel("PCA1")
ax.set_ylabel("PCA2")
ax.set_zlabel("PCA3")
ax.set_title("3D Projection")
#Just change the n_components value to 3 for 3D visualization in PCA





from sklearn.cluster import KMeans
from kneed import KneeLocator


wcss=[]
for i in range (1,11):
    kmeans=KMeans(n_clusters=i, random_state=42)
    kmeans.fit_predict(X_pca)
    wcss.append(kmeans.inertia_)


knee = KneeLocator(range(1,11), wcss, curve="convex", direction="decreasing")

optimal_k = knee.elbow


print(optimal_k)


# Plot

plt.plot(range(1,11), wcss, marker="o")
plt.xlabel("K")
plt.ylabel("WCSS")





from sklearn.metrics import silhouette_score

ss=[]

for i in range (2,11):
    kmeans=KMeans(n_clusters=i, random_state=42)
    labels=kmeans.fit_predict(X_pca)
    ss.append(silhouette_score(X_pca, labels))


# Plot

plt.plot(range(2,11), ss, marker="o")
plt.xlabel("K")
plt.ylabel("Silhouette Score")


# wcss and ss together 

k_range = range(2,11)

fig, ax1 = plt.subplots(figsize=(8,6))

ax1.plot(k_range, wcss[:len(k_range)], marker="o", color="blue")
ax1.set_xlabel("K")
ax1.set_ylabel("WCSS")

ax2=ax1.twinx()
ax2.plot(k_range, ss[:len(k_range)], marker="x", color="red", linestyle="--")
ax2.set_ylabel("SS")

plt.title("WCSS + SS")





# Kmeans

kmeans = KMeans(n_clusters=4, random_state=42)
labels_kmeans = kmeans.fit_predict(X_pca) 


fig = plt.figure(figsize=(8,6))

ax = fig.add_subplot(111, projection="3d")

ax.scatter(X_pca[:,0], X_pca[:,1], X_pca[:,2], c=labels_kmeans)


# Agglomerative clustering

from sklearn.cluster import AgglomerativeClustering


agg_clf = AgglomerativeClustering(n_clusters=4, linkage="ward")
labels_agg = agg_clf.fit_predict(X_pca)


fig = plt.figure(figsize=(8,6))

ax = fig.add_subplot(111, projection="3d")

ax.scatter(X_pca[:,0], X_pca[:,1], X_pca[:,2], c=labels_agg)



