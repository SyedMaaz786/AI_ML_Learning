


import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import DBSCAN
from sklearn.datasets import make_moons


X, y = make_moons(
    n_samples=500,
    noise=0.1,
    random_state=42
)


scaler = StandardScaler()
X_scale = scaler.fit_transform(X)


# Visualise
sns.scatterplot(x=X_scale[:,0], y=X_scale[:,1])





dbscan = DBSCAN(
    eps=0.2,
    min_samples=5
)

labels = dbscan.fit_predict(X_scale)
sns.scatterplot(x=X_scale[:,0], y=X_scale[:,1], c=labels)





import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler


df = pd.read_csv("thyroid_dataset.csv")


df.head()


df.shape


X = df.drop(columns="Outlier_label")
y = df["Outlier_label"]


X.head()


X.shape


scaler = StandardScaler()
X_scale = scaler.fit_transform(X)


from sklearn.ensemble import IsolationForest

model = IsolationForest(
    n_estimators=200,
    contamination="auto",
    random_state=42
)


labels = model.fit_predict(X_scale)


# Visualize
# Here we are using PCA because we wanted to do dimensionality reduction from 21 dimensions we choose only 2

from sklearn.decomposition import PCA

pca = PCA(
    n_components=2
)
X_pca = pca.fit_transform(X_scale)
X_pca.shape


plt.figure(figsize=(8,6))
plt.xlabel("PC1")
plt.ylabel("PC2")

plt.scatter(x=X_pca[:,0], y=X_pca[:,1], c=labels)


# checking number of outliers and normal pts

import numpy as np

n_outliers = np.sum(labels == -1)
n_normal = np.sum(labels == 1)

print("Outliers:", n_outliers)
print("Normal pts:", n_normal)





from sklearn.neighbors import LocalOutlierFactor

model = LocalOutlierFactor()
labels = model.fit_predict(X_scale)


plt.figure(figsize=(8,6))
plt.xlabel("PC1")
plt.ylabel("PC2")

plt.scatter(x=X_pca[:,0], y=X_pca[:,1], c=labels)



