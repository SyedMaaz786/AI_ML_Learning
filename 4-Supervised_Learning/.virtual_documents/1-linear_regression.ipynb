import pandas as pd
import seaborn as sns


insurance_data = pd.read_csv("insurance.csv")
insurance_data


X = insurance_data.drop(columns=["region","charges"])
y = insurance_data["charges"] #output feature


X.head()


X["sex"] = X["sex"].map({"male": 1, "female": 0})
X["smoker"] = X["smoker"].map({"yes": 1, "no": 0})


X.head()


#Train Test split
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)



#Train model

from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(X_train, y_train)


#Prediction
y_pred = model.predict(X_test)


#Evaluation metrics (checking accuracy)
#r2
from sklearn.metrics import r2_score

r2 = r2_score(y_test, y_pred)
print("r2:",r2)

#adjusted r2
n = X_test.shape[0]  #Check notes if any dought
p = X_test.shape[1]

adjusted_r2 = 1-(1-r2) * (n-1) / (n-p-1)  #This is nothing but the formula
print("adjusted r2:",adjusted_r2)


#Feature Engineering
# One Hot Encoding
X = insurance_data.drop(columns=["charges"])
y = insurance_data["charges"]

X = pd.get_dummies(X, columns=["region"], drop_first=True, dtype=int) #This line is one hot encoding

X["sex"] = X["sex"].map({"male": 1, "female": 0})
X["smoker"] = X["smoker"].map({"yes": 1, "no": 0})



X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)
y_pred=model.predict(X_test)

r2=r2_score(y_test, y_pred)
print("r2:",r2)


#Interaction Features
X = insurance_data.drop(columns=["charges"])
y = insurance_data["charges"]

X = pd.get_dummies(X, columns=["region"], drop_first=True, dtype=int)

X["sex"] = X["sex"].map({"male": 1, "female": 0})
X["smoker"] = X["smoker"].map({"yes": 1, "no": 0})

X["age_smoker"] = X["age"] * X["smoker"]  #This is interaction features
X["bmi_smoker"] = X["bmi"] * X["smoker"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)
y_pred=model.predict(X_test)

r2=r2_score(y_test, y_pred)
print("r2:",r2)


#Overfit VS Underfit
# training is high, testing is low - Overfit
# training is low and testing is low - Undefit

y_train_pred = model.predict(X_train)
r2_train=r2_score(y_train, y_train_pred)

y_test_pred = model.predict(X_test)
r2_test=r2_score(y_test, y_test_pred)

print("training result:", r2_train)
print("training result:", r2_test)





from sklearn.linear_model import Lasso, Ridge
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd
from sklearn.model_selection import train_test_split


insurance_data = pd.read_csv("insurance.csv")

X = insurance_data.drop(columns=["charges"])
y = insurance_data["charges"]

X = pd.get_dummies(X, columns=["region"], drop_first=True, dtype=int)

X["sex"] = X["sex"].map({"male": 1, "female": 0})
X["smoker"] = X["smoker"].map({"yes": 1, "no": 0})

X["age_smoker"] = X["age"] * X["smoker"] 
X["bmi_smoker"] = X["bmi"] * X["smoker"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)



#Creating Lasso model

lasso_model = Lasso(alpha = 0.5)  #Here alpha is nothing but λ (Check notes)
lasso_model.fit(X_train, y_train)

y_pred = lasso_model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print("mse:", mse)


#Creating Ridge model

ridge_model = Ridge(alpha = 0.5)  #Here alpha is nothing but λ (Check notes)
ridge_model.fit(X_train, y_train)

y_pred = ridge_model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print("mse:", mse)


#Creating lassoCV model

from sklearn.linear_model import LassoCV
a = [0.001, 0.1, 2, 4, 6, 8, 10, 30, 50, 70, 100]  #Here we have used multiple alpha values so that we can perform cross validation.

lasso_cv_model = LassoCV(  #This is the model creation 
    alphas=a,               #which takes these all parameters
    cv=5,
    max_iter=1000,
    random_state=42
)

lasso_cv_model.fit(X_train, y_train)

print("best alpha: ", lasso_cv_model.alpha_)

y_pred = lasso_cv_model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print("mse:", mse)
print("r2:", r2)


# Creating RidgeCV model

from sklearn.linear_model import RidgeCV
from sklearn.metrics import mean_squared_error, r2_score

a = [0.001, 0.1, 2, 4, 6, 8, 10, 30, 50, 70, 100]  
# Multiple alpha values for cross-validation

ridge_cv_model = RidgeCV(     # Model creation
    alphas=a,                # List of alpha values to try
    cv=5                     # 5-fold cross validation
)

ridge_cv_model.fit(X_train, y_train)

print("best alpha:", ridge_cv_model.alpha_)

y_pred = ridge_cv_model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("mse:", mse)
print("r2:", r2)

