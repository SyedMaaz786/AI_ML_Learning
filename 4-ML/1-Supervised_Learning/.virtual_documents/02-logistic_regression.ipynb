import pandas as pd
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score


df = pd.read_csv("heart.csv")
df.head()


X = df.drop(columns="target", axis=1)
y = df["target"]
X.head()


y.head()


# train test split 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

#model
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)



#Remember for classification models the binary ie(0,1) should be near to 50-50, if not our model may become bias.

y_train[y_train == 1] #133
y_train[y_train == 0] #109


y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
print("accuracy:", accuracy)
print("precision:", precision)


# Evaluation metrix (confusion matrix)

from sklearn.metrics import confusion_matrix, classification_report

cm = confusion_matrix(y_test, y_pred)
print("cm:", cm)
print(classification_report(y_test, y_pred))


#Scaling (standardization)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scale = scaler.fit_transform(X_train)  #if any dought check in notes.
X_test_scale = scaler.transform(X_test)
X_train_scale


model.fit(X_train_scale, y_train)
y_pred = model.predict(X_test_scale)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
print("accuracy:", accuracy)
print("precision", precision)
